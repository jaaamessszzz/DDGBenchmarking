{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Analysis of RosettaScript PDB Output\n",
    "The goal of this notebook is to develop a general method for correlating structural variation in RosettaScript output (i.e. RMSD) with interesting factors (DDG scores, ensemble size, trial sizes, kT).<br>\n",
    "<br>\n",
    "<b>Things to think about:</b>\n",
    "* How much backbone variation is required/useful?\n",
    "* Input starting PDB, WT output PDBs, and mutant output PDBs\n",
    "* All-vs-all RMSDs for any outputs (DDG WT, DDG mutants, minimization comparison structures)\n",
    "* RMSD for 8A repack sphere (repacking) and overall structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Kyle's RMSD Script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "program_description = \"Script to calculate pairwise RMSD of ensemble\"\n",
    "\n",
    "# Use pyRMSD for RMSD calculations if available as it's much faster than BioPython\n",
    "try:\n",
    "    import pyRMSD\n",
    "    from pyRMSD.matrixHandler import MatrixHandler\n",
    "    import pyRMSD.RMSDCalculator\n",
    "    from pyRMSD.availableCalculators import availableCalculators\n",
    "    # Use CUDA for GPU calculations, if avialable\n",
    "    if 'QCP_CUDA_MEM_CALCULATOR' in availableCalculators():\n",
    "        pyrmsd_calc = 'QCP_CUDA_MEM_CALCULATOR'\n",
    "    else:\n",
    "        pyrmsd_calc = 'QCP_SERIAL_CALCULATOR'\n",
    "except ImportError:\n",
    "    print 'Warning: could not import faster RMSD module. Falling back to slower biopython...'\n",
    "    pyRMSD = None\n",
    "    import Bio.PDB\n",
    "    import Bio.PDB.Atom as Atom\n",
    "\n",
    "def calc_rms(ref_coords, alt_coords):\n",
    "    # print ref_coords, alt_coords\n",
    "    assert( len(ref_coords) == len(alt_coords) )\n",
    "    if pyRMSD:\n",
    "        calculator = pyRMSD.RMSDCalculator.RMSDCalculator(pyrmsd_calc, np.array([ref_coords, alt_coords]))\n",
    "        return calculator.pairwiseRMSDMatrix()[0]\n",
    "    else:\n",
    "        super_imposer = Bio.PDB.Superimposer()\n",
    "        ref_atoms = [Atom.Atom('CA', coords, 0.0, 1.0, '', ' CA ', i+1, element='C') for i, coords in enumerate(ref_coords)]\n",
    "        alt_atoms = [Atom.Atom('CA', coords, 0.0, 1.0, '', ' CA ', i+1, element='C') for i, coords in enumerate(alt_coords)]\n",
    "        super_imposer.set_atoms(ref_atoms, alt_atoms)\n",
    "        return super_imposer.rms\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=program_description)\n",
    "\n",
    "    parser.add_argument('-d', '--database_input',\n",
    "                        nargs = '+',\n",
    "                        help = 'Database to read coordinates from')\n",
    "    parser.add_argument('-f', '--folder',\n",
    "                        nargs = '+',\n",
    "                        help = 'Folder to search for PDB files')\n",
    "    parser.add_argument('-p', '--pdb_file',\n",
    "                        nargs = '+',\n",
    "                        help = 'PDB file to cluster')\n",
    "    parser.add_argument('--single_thread',\n",
    "                        default = False,\n",
    "                        action = 'store_true',\n",
    "                        help = 'Do not use multiprocessing')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.single_thread:\n",
    "        cpu_count = 1\n",
    "    else:\n",
    "        cpu_count = multiprocessing.cpu_count()\n",
    "        pool = multiprocessing.Pool(cpu_count)\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    print 'Starting calculating RMS for all paths vs. all first fragments for each position'\n",
    "    total_count = len(path_data)\n",
    "    starting_time = time.time()\n",
    "\n",
    "    def helper_callback(outer_results):\n",
    "        for results_tuple in outer_results:\n",
    "            path_number, rms_results = results_tuple\n",
    "            results_dict[path_number] = rms_results\n",
    "\n",
    "    path_nums_for_jobs = [[] for x in xrange(cpu_count)]\n",
    "    path_coords_for_jobs = [[] for x in xrange(cpu_count)]\n",
    "    for i, path_coords in enumerate([[anchor_points[x] for x in path] for path in path_data]):\n",
    "        path_nums_for_jobs[ i%cpu_count ].append( i )\n",
    "        path_coords_for_jobs[ i%cpu_count ].append( path_coords )\n",
    "\n",
    "    for path_nums_list, path_coords_list in zip(path_nums_for_jobs, path_coords_for_jobs):\n",
    "        if args.single_thread:\n",
    "            helper_callback( paths_against_all_fragments(path_nums_list, path_coords_list, starting_time, total_count, path_length) )\n",
    "        else:\n",
    "            pool.apply_async(paths_against_all_fragments, (path_nums_list, path_coords_list, starting_time, total_count, path_length), callback=helper_callback)\n",
    "\n",
    "    if not args.single_thread:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    n = int(reporter_n.value)\n",
    "    completion_time = time.time()\n",
    "    print 'Finished! Processed %d %s, took %.3f seconds\\n' % (n, 'paths', completion_time-starting_time)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
