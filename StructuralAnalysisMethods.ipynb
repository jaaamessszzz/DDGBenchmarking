{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.107679458755\n"
     ]
    }
   ],
   "source": [
    "from Bio.PDB import *\n",
    "import os\n",
    "\n",
    "#import pyRMSD\n",
    "#from pyRMSD.matrixHandler import MatrixHandler\n",
    "#import pyRMSD.RMSDCalculator\n",
    "#from pyRMSD.availableCalculators import availableCalculators\n",
    "\n",
    "#From Kyle's Finalize.py\n",
    "def read_mutations_resfile(filenum_dir):\n",
    "    resfile = os.path.join(filenum_dir, 'mutations_repack.resfile')\n",
    "    mutations = []\n",
    "    with open(resfile, 'r') as f:\n",
    "        post_start = False\n",
    "        for line in f:\n",
    "            if post_start:\n",
    "                line = line.strip()\n",
    "                pdb_resnum, chain, pikaa, mut_res = line.split()\n",
    "                mutations.append( [pdb_resnum, chain, pikaa, mut_res] )\n",
    "            elif line.startswith('start'):\n",
    "                post_start = True\n",
    "    return mutations\n",
    "\n",
    "#From Kyle's Finalize.py\n",
    "def find_neighbors(filenum_dir, pdb_path, neighbor_distance = 8.0):\n",
    "    mutations = read_mutations_resfile(filenum_dir)\n",
    "    open_filename = pdb_path\n",
    "    parser = PDBParser(PERMISSIVE=1)\n",
    "    open_strct = parser.get_structure('Open', open_filename)\n",
    "\n",
    "    # There should only be one model in PDB file\n",
    "    num_models = 0\n",
    "    for model in open_strct.get_models():\n",
    "        num_models += 1\n",
    "    assert( num_models == 1 )\n",
    "\n",
    "    chain_list = [chain.get_id() for chain in open_strct[0].get_chains()]\n",
    "    neighbors = set()\n",
    "    for mutation in mutations:\n",
    "        res_id, chain_id, pikaa, mut_aa = mutation\n",
    "        mut_chain = str(chain_id)\n",
    "        try:\n",
    "            mut_pos = int( res_id )\n",
    "            mut_insertion_code = ' '\n",
    "        except ValueError:\n",
    "            mut_pos = int( res_id[:-1] )\n",
    "            mut_insertion_code = res_id[-1]\n",
    "\n",
    "        mut_residue = open_strct[0][mut_chain][(' ', mut_pos, mut_insertion_code)]\n",
    "        for chain in chain_list:\n",
    "            for residue in [res.get_id() for res in open_strct[0][chain].get_residues()]:\n",
    "                try:\n",
    "                    # Kyle note - might be good to do something else for consistency, since not all residues have CB\n",
    "                    dist = mut_residue['CB'] - open_strct[0][chain][residue]['CB']\n",
    "                    if dist < neighbor_distance:\n",
    "                        neighbors.add( (residue, chain) )\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "#Residue list generator\n",
    "def generate_lists(reslist, ref_struc, alt_struc):\n",
    "    ref_atoms = []\n",
    "    alt_atoms = []\n",
    "\n",
    "    for res in reslist:\n",
    "        for ref_atom in ref_struc.get_atoms():\n",
    "            if ref_atom.get_parent().get_full_id()[2] == res[1]:\n",
    "                if str(ref_atom.get_parent().get_full_id()[3][1]) == str(res[0]):\n",
    "                    if 'H' in ref_atom.get_id():\n",
    "                        if 'O' in ref_atom.get_id() or 'N' in ref_atom.get_id():\n",
    "                            ref_atoms.append(ref_atom)\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        ref_atoms.append(ref_atom)\n",
    "        \n",
    "        for alt_atom in alt_struc.get_atoms():    \n",
    "            if alt_atom.get_parent().get_full_id()[2] == res[1]:\n",
    "                if str(alt_atom.get_parent().get_full_id()[3][1]) == str(res[0]):     \n",
    "                    if 'H' in alt_atom.get_id():\n",
    "                        if 'O' in alt_atom.get_id() or 'N' in alt_atom.get_id():\n",
    "                            alt_atoms.append(alt_atom)\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        alt_atoms.append(alt_atom)\n",
    "    \n",
    "    return ref_atoms, alt_atoms\n",
    "\n",
    "#Calculates global CA rmsd (Only guarenteed to work on identical structures!!!!)\n",
    "#By identical I mean the same starting PDBs but one had some movers applied to it\n",
    "def rms_global(ref_struc, alt_struc):\n",
    "\n",
    "    ref_atoms = []\n",
    "    alt_atoms = []\n",
    "    \n",
    "    for ref_atom in ref_struc.get_atoms():\n",
    "        if ref_atom.get_name() == 'CA':\n",
    "            ref_atoms.append(ref_atom)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    for alt_atom in alt_struc.get_atoms():\n",
    "        if alt_atom.get_name() == 'CA':\n",
    "            alt_atoms.append(alt_atom)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    super_imposer = Bio.PDB.Superimposer()\n",
    "    super_imposer.set_atoms(ref_atoms, alt_atoms)\n",
    "    \n",
    "    return super_imposer.rms\n",
    "\n",
    "#ALLxALL Global RMSD\n",
    "def all_by_all(datadir):\n",
    "    parser = PDBParser()\n",
    "    all_rmsd = []\n",
    "    for i in enumerate(os.listdir(datadir)):\n",
    "        if i[1].endswith('.pdb'):\n",
    "            for j in enumerate(os.listdir(datadir)):\n",
    "                if j[1].endswith('.pdb'):\n",
    "                    if i[0]>j[0]:\n",
    "                        structure_ref = parser.get_structure('Ref', 'TestJobs/output/59648/%s' % i[1])\n",
    "                        structure_target = parser.get_structure('Target', 'TestJobs/output/59648/%s' % j[1])\n",
    "\n",
    "                        RMSD = rms_global(structure_ref, structure_target)\n",
    "                        print '%s:%s = %s' %( j[1][9:-4], i[1][9:-4], RMSD)\n",
    "                        all_rmsd.append(RMSD)\n",
    "    return all_rmsd\n",
    "\n",
    "#Neighborhood RMSD\n",
    "def rms_neighborhood(neighbors, ref_struc, alt_struc):\n",
    "    ref_atoms, alt_atoms = generate_lists(neighbors, ref_struc, alt_struc)\n",
    "    \n",
    "    def getKey(item):\n",
    "        return item.get_full_id()[4][0]\n",
    "    \n",
    "    ref_atoms = sorted(ref_atoms, key=getKey)\n",
    "    alt_atoms = sorted(alt_atoms, key=getKey)\n",
    "    \n",
    "    super_imposer = Bio.PDB.Superimposer()\n",
    "    super_imposer.set_atoms(ref_atoms, alt_atoms)\n",
    "\n",
    "    return super_imposer.rms\n",
    "\n",
    "#Calculates sidechain rmsd        \n",
    "def rms_mutation(filenum_dir, ref_struc, alt_struc):\n",
    "    mutations = read_mutations_resfile(filenum_dir)\n",
    "    ref_atoms, alt_atoms = generate_lists(mutations, ref_struc, alt_struc)\n",
    "    \n",
    "    def getKey(item):\n",
    "        return item.get_full_id()[4][0]\n",
    "    \n",
    "    ref_atoms = sorted(ref_atoms, key=getKey)\n",
    "    alt_atoms = sorted(alt_atoms, key=getKey)\n",
    "\n",
    "    ref_atoms_coord = []\n",
    "    alt_atoms_coord = []\n",
    "    \n",
    "    for i in ref_atoms:\n",
    "        ref_atoms_coord.append(i.get_coord())\n",
    "    for i in alt_atoms:\n",
    "        alt_atoms_coord.append(i.get_coord())\n",
    "    \n",
    "    super_imposer = Bio.PDB.Superimposer()\n",
    "    super_imposer.set_atoms(ref_atoms, alt_atoms)\n",
    "        \n",
    "    return super_imposer.rms\n",
    "\n",
    "#Input structure (for now, should transfer to a different function later)\n",
    "def simple_input():\n",
    "    parser = PDBParser()\n",
    "    structure_ref = parser.get_structure('Ref', 'TestJobs/data/59648/1TM1_EI.pdb')\n",
    "    structure_target = parser.get_structure('Target', 'TestJobs/output/59648/1TM1_EI_0003.pdb')\n",
    "    return structure_ref, structure_target\n",
    "\n",
    "#Define things\n",
    "datadir = 'TestJobs/output/59648'\n",
    "filenum_dir = 'TestJobs/data/59648/'\n",
    "pdb_path = 'TestJobs/data/59648/1TM1_EI.pdb'\n",
    "neighbors = find_neighbors(filenum_dir, pdb_path, 8)\n",
    "\n",
    "#Action!!!\n",
    "def main():\n",
    "    #all_by_all(datadir)\n",
    "    structure_ref, structure_target = simple_input()\n",
    "    #rms_global(structure_ref, structure_target)\n",
    "    #rms_neighborhood(neighbors, structure_ref, structure_target)\n",
    "    print rms_mutation(filenum_dir, structure_ref, structure_target)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Analysis of RosettaScript PDB Output\n",
    "The goal of this notebook is to develop a general method for correlating structural variation in RosettaScript output (i.e. RMSD) with interesting factors (DDG scores, ensemble size, trial sizes, kT).<br>\n",
    "<br>\n",
    "<b>Things to think about:</b>\n",
    "* How much backbone variation is required/useful?\n",
    "* Input starting PDB, WT output PDBs, and mutant output PDBs\n",
    "* All-vs-all RMSDs for any outputs (DDG WT, DDG mutants, minimization comparison structures)\n",
    "* RMSD for 8A repack sphere (repacking) and overall structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Kyle's RMSD Script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "program_description = \"Script to calculate pairwise RMSD of ensemble\"\n",
    "\n",
    "# Use pyRMSD for RMSD calculations if available as it's much faster than BioPython\n",
    "try:\n",
    "    import pyRMSD\n",
    "    from pyRMSD.matrixHandler import MatrixHandler\n",
    "    import pyRMSD.RMSDCalculator\n",
    "    from pyRMSD.availableCalculators import availableCalculators\n",
    "    # Use CUDA for GPU calculations, if avialable\n",
    "    if 'QCP_CUDA_MEM_CALCULATOR' in availableCalculators():\n",
    "        pyrmsd_calc = 'QCP_CUDA_MEM_CALCULATOR'\n",
    "    else:\n",
    "        pyrmsd_calc = 'QCP_SERIAL_CALCULATOR'\n",
    "except ImportError:\n",
    "    print 'Warning: could not import faster RMSD module. Falling back to slower biopython...'\n",
    "    pyRMSD = None\n",
    "    import Bio.PDB\n",
    "    import Bio.PDB.Atom as Atom\n",
    "\n",
    "def calc_rms(ref_coords, alt_coords):\n",
    "    # print ref_coords, alt_coords\n",
    "    assert( len(ref_coords) == len(alt_coords) )\n",
    "    if pyRMSD:\n",
    "        calculator = pyRMSD.RMSDCalculator.RMSDCalculator(pyrmsd_calc, np.array([ref_coords, alt_coords]))\n",
    "        return calculator.pairwiseRMSDMatrix()[0]\n",
    "    else:\n",
    "        super_imposer = Bio.PDB.Superimposer()\n",
    "        ref_atoms = [Atom.Atom('CA', coords, 0.0, 1.0, '', ' CA ', i+1, element='C') for i, coords in enumerate(ref_coords)]\n",
    "        alt_atoms = [Atom.Atom('CA', coords, 0.0, 1.0, '', ' CA ', i+1, element='C') for i, coords in enumerate(alt_coords)]\n",
    "        super_imposer.set_atoms(ref_atoms, alt_atoms)\n",
    "        return super_imposer.rms\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=program_description)\n",
    "\n",
    "    parser.add_argument('-d', '--database_input',\n",
    "                        nargs = '+',\n",
    "                        help = 'Database to read coordinates from')\n",
    "    parser.add_argument('-f', '--folder',\n",
    "                        nargs = '+',\n",
    "                        help = 'Folder to search for PDB files')\n",
    "    parser.add_argument('-p', '--pdb_file',\n",
    "                        nargs = '+',\n",
    "                        help = 'PDB file to cluster')\n",
    "    parser.add_argument('--single_thread',\n",
    "                        default = False,\n",
    "                        action = 'store_true',\n",
    "                        help = 'Do not use multiprocessing')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.single_thread:\n",
    "        cpu_count = 1\n",
    "    else:\n",
    "        cpu_count = multiprocessing.cpu_count()\n",
    "        pool = multiprocessing.Pool(cpu_count)\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    print 'Starting calculating RMS for all paths vs. all first fragments for each position'\n",
    "    total_count = len(path_data)\n",
    "    starting_time = time.time()\n",
    "\n",
    "    def helper_callback(outer_results):\n",
    "        for results_tuple in outer_results:\n",
    "            path_number, rms_results = results_tuple\n",
    "            results_dict[path_number] = rms_results\n",
    "\n",
    "    path_nums_for_jobs = [[] for x in xrange(cpu_count)]\n",
    "    path_coords_for_jobs = [[] for x in xrange(cpu_count)]\n",
    "    for i, path_coords in enumerate([[anchor_points[x] for x in path] for path in path_data]):\n",
    "        path_nums_for_jobs[ i%cpu_count ].append( i )\n",
    "        path_coords_for_jobs[ i%cpu_count ].append( path_coords )\n",
    "\n",
    "    for path_nums_list, path_coords_list in zip(path_nums_for_jobs, path_coords_for_jobs):\n",
    "        if args.single_thread:\n",
    "            helper_callback( paths_against_all_fragments(path_nums_list, path_coords_list, starting_time, total_count, path_length) )\n",
    "        else:\n",
    "            pool.apply_async(paths_against_all_fragments, (path_nums_list, path_coords_list, starting_time, total_count, path_length), callback=helper_callback)\n",
    "\n",
    "    if not args.single_thread:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    n = int(reporter_n.value)\n",
    "    completion_time = time.time()\n",
    "    print 'Finished! Processed %d %s, took %.3f seconds\\n' % (n, 'paths', completion_time-starting_time)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
