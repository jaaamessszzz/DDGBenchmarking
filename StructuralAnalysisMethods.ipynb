{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Analysis of RosettaScript PDB Output\n",
    "The goal of this notebook is to develop a general method for correlating structural variation in RosettaScript output (i.e. RMSD) with interesting factors (DDG scores, ensemble size, trial sizes, kT).<br>\n",
    "<br>\n",
    "<b>Things to think about:</b>\n",
    "* How much backbone variation is required/useful?\n",
    "* Input starting PDB, WT output PDBs, and mutant output PDBs\n",
    "* All-vs-all RMSDs for any outputs (DDG WT, DDG mutants, minimization comparison structures)\n",
    "* RMSD for 8A repack sphere (repacking) and overall structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "import Bio.PDB\n",
    "import os\n",
    "import pyRMSD\n",
    "from pyRMSD.matrixHandler import MatrixHandler\n",
    "import pyRMSD.RMSDCalculator\n",
    "from pyRMSD.availableCalculators import availableCalculators\n",
    "import prody\n",
    "import numpy as np\n",
    "import scipy.spatial.distance\n",
    "\n",
    "#From Kyle's Finalize.py\n",
    "def read_mutations_resfile(filenum_dir):\n",
    "    resfile = os.path.join(filenum_dir, 'mutations_repack.resfile')\n",
    "    mutations = []\n",
    "    with open(resfile, 'r') as f:\n",
    "        post_start = False\n",
    "        for line in f:\n",
    "            if post_start:\n",
    "                line = line.strip()\n",
    "                pdb_resnum, chain, pikaa, mut_res = line.split()\n",
    "                mutations.append( [pdb_resnum, chain, pikaa, mut_res] )\n",
    "            elif line.startswith('start'):\n",
    "                post_start = True\n",
    "    return mutations\n",
    "\n",
    "#From Kyle's Finalize.py\n",
    "def find_neighbors(filenum_dir, pdb_path, neighbor_distance = 8.0):\n",
    "    mutations = read_mutations_resfile(filenum_dir)\n",
    "    parser = PDBParser(PERMISSIVE=1)\n",
    "    open_strct = parser.get_structure('Open', pdb_path)\n",
    "\n",
    "    # There should only be one model in PDB file\n",
    "    num_models = 0\n",
    "    for model in open_strct.get_models():\n",
    "        num_models += 1\n",
    "    assert( num_models == 1 )\n",
    "\n",
    "    chain_list = [chain.get_id() for chain in open_strct[0].get_chains()]\n",
    "    neighbors = set()\n",
    "    for mutation in mutations:\n",
    "        res_id, chain_id, pikaa, mut_aa = mutation\n",
    "        mut_chain = str(chain_id)\n",
    "        try:\n",
    "            mut_pos = int( res_id )\n",
    "            mut_insertion_code = ' '\n",
    "        except ValueError:\n",
    "            mut_pos = int( res_id[:-1] )\n",
    "            mut_insertion_code = res_id[-1]\n",
    "\n",
    "        mut_residue = open_strct[0][mut_chain][(' ', mut_pos, mut_insertion_code)]\n",
    "        for chain in chain_list:\n",
    "            for residue in [res.get_id() for res in open_strct[0][chain].get_residues()]:\n",
    "                try:\n",
    "                    # Kyle note - might be good to do something else for consistency, since not all residues have CB\n",
    "                    dist = mut_residue['CB'] - open_strct[0][chain][residue]['CB']\n",
    "                    if dist < neighbor_distance:\n",
    "                        neighbors.add( (residue, chain) )\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        dist = mut_residue['CA'] - open_strct[0][chain][residue]['CA']\n",
    "                        if dist < neighbor_distance:\n",
    "                            neighbors.add( (residue, chain) )\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "#Kyle's RMSDWrapper.py (Spread out al over the place now)\n",
    "def rmsd(input_pdbs, pyrmsd_calc, coordinates):\n",
    "    if type(coordinates) is dict:\n",
    "        rmsd_list = []\n",
    "        for mutres, coord_set in coordinates.iteritems():\n",
    "            rmsd_matrix = pyRMSD.matrixHandler.MatrixHandler().createMatrix(coord_set, pyrmsd_calc)\n",
    "            rmsd_list.append([mutres, scipy.spatial.distance.squareform( rmsd_matrix.get_data() )])\n",
    "        return rmsd_list\n",
    "    else:\n",
    "        rmsd_matrix = pyRMSD.matrixHandler.MatrixHandler().createMatrix(coordinates, pyrmsd_calc)\n",
    "        return [scipy.spatial.distance.squareform( rmsd_matrix.get_data() )]\n",
    "    \n",
    "def global_ca_rms(input_pdbs):\n",
    "    coordinates = np.array( [prody.parsePDB(input_pdb).select('calpha').getCoords() for input_pdb in input_pdbs] )\n",
    "    return coordinates    \n",
    "    \n",
    "def neighborhood_rms(neighbors, reference, input_pdbs):\n",
    "    temp = []\n",
    "\n",
    "    for input_pdb in input_pdbs:\n",
    "        atom_list = []\n",
    "        hv = prody.parsePDB(input_pdb).getHierView()\n",
    "        res_list = sorted( [hv[neighbor[1], neighbor[0][1]] for neighbor in neighbors] )\n",
    "        for res in res_list:\n",
    "            for atom in res:\n",
    "                if atom.getElement() != 'H':\n",
    "                    print atom\n",
    "                    atom_list.append(atom.getCoords())\n",
    "                else:\n",
    "                    pass\n",
    "        temp.append(atom_list)\n",
    "        \n",
    "    coordinates = np.asarray(temp)\n",
    "    return coordinates\n",
    "        \n",
    "#Calculates sidechain rmsd        \n",
    "def mutant_rms(datadir, input_pdbs):\n",
    "    mutations = read_mutations_resfile(datadir)\n",
    "    mutation_dict = {}\n",
    "    \n",
    "    for mutation in mutations:\n",
    "        temp = []\n",
    "        temp_nparray = []\n",
    "        \n",
    "        for input_pdb in input_pdbs: \n",
    "            atom_list = []\n",
    "            hv = prody.parsePDB(input_pdb).getHierView()\n",
    "            res_list = [hv[mutation[1], int(mutation[0])]]\n",
    "            for res in res_list:\n",
    "                for atom in res:\n",
    "                    if atom.getElement() != 'H':\n",
    "                        atom_list.append(atom.getCoords())\n",
    "                    else:\n",
    "                        pass\n",
    "            temp.append(atom_list)\n",
    "        \n",
    "        temp_nparray = np.asarray(temp)\n",
    "        \n",
    "        mutation_dict['%s%s' %(mutation[1], mutation[0])] = temp_nparray\n",
    "    print mutation_dict.keys()\n",
    "    return mutation_dict\n",
    "\n",
    "#Action!!!\n",
    "def main():\n",
    "    os.chdir('/home/james.lucas/Rotation/DDGBenchmarks_Test/')\n",
    "    \n",
    "    #Define things\n",
    "    datadir = 'TestJobs/data/59648/'\n",
    "    reference = 'TestJobs/data/59648/1TM1_EI.pdb'\n",
    "    outputdir = 'TestJobs/output/59648/'\n",
    "    \n",
    "    # Use CUDA for GPU calculations, if avialable\n",
    "    if 'QCP_CUDA_MEM_CALCULATOR' in availableCalculators():\n",
    "        pyrmsd_calc = 'QCP_CUDA_MEM_CALCULATOR'\n",
    "    else:\n",
    "        pyrmsd_calc = 'QCP_SERIAL_CALCULATOR'\n",
    "    \n",
    "    input_temp = []\n",
    "    for i in os.listdir(outputdir):\n",
    "        if i.endswith('.pdb'):\n",
    "            input_temp.append(os.path.join(outputdir, i ))\n",
    "    input_pdbs = sorted(input_temp)\n",
    "    \n",
    "    neighbors = find_neighbors(datadir, reference, 8)\n",
    "    \n",
    "    point_mutants = mutant_rms(datadir, input_pdbs)\n",
    "    #neighborhood = neighborhood_rms(neighbors, reference, input_pdbs)\n",
    "    #global_ca = global_ca_rms(input_pdbs)\n",
    "    #\n",
    "    #asdf = rmsd(input_pdbs, pyrmsd_calc, point_mutants)\n",
    "    #\n",
    "    #for i in asdf:\n",
    "    #    print i\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> 4998 atoms and 1 coordinate set(s) were parsed in 0.03s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['61', 'I', 'PIKAA', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> 4998 atoms and 1 coordinate set(s) were parsed in 0.19s.\n",
      "@> 4998 atoms and 1 coordinate set(s) were parsed in 0.13s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'61I': {'1': [179.054583901716, 73.195873562246803], '3': [179.054583901716, 73.195873562246803], '2': [179.054583901716, 73.195873562246803]}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from prody import *\n",
    "#from Bio.PDB import *\n",
    "\n",
    "#From Kyle's Finalize.py\n",
    "def read_mutations_resfile(filenum_dir):\n",
    "    resfile = os.path.join(filenum_dir, 'mutations_repack.resfile')\n",
    "    mutations = []\n",
    "    with open(resfile, 'r') as f:\n",
    "        post_start = False\n",
    "        for line in f:\n",
    "            if post_start:\n",
    "                line = line.strip()\n",
    "                pdb_resnum, chain, pikaa, mut_res = line.split()\n",
    "                mutations.append( [pdb_resnum, chain, pikaa, mut_res] )\n",
    "            elif line.startswith('start'):\n",
    "                post_start = True\n",
    "    return mutations\n",
    "\n",
    "#From Kyle's Finalize.py\n",
    "def find_neighbors(filenum_dir, pdb_path, neighbor_distance = 8.0):\n",
    "    mutations = read_mutations_resfile(filenum_dir)\n",
    "    parser = PDBParser(PERMISSIVE=1)\n",
    "    open_strct = parser.get_structure('Open', pdb_path)\n",
    "\n",
    "    # There should only be one model in PDB file\n",
    "    num_models = 0\n",
    "    for model in open_strct.get_models():\n",
    "        num_models += 1\n",
    "    assert( num_models == 1 )\n",
    "\n",
    "    chain_list = [chain.get_id() for chain in open_strct[0].get_chains()]\n",
    "    neighbors = set()\n",
    "    for mutation in mutations:\n",
    "        res_id, chain_id, pikaa, mut_aa = mutation\n",
    "        mut_chain = str(chain_id)\n",
    "        try:\n",
    "            mut_pos = int( res_id )\n",
    "            mut_insertion_code = ' '\n",
    "        except ValueError:\n",
    "            mut_pos = int( res_id[:-1] )\n",
    "            mut_insertion_code = res_id[-1]\n",
    "\n",
    "        mut_residue = open_strct[0][mut_chain][(' ', mut_pos, mut_insertion_code)]\n",
    "        for chain in chain_list:\n",
    "            for residue in [res.get_id() for res in open_strct[0][chain].get_residues()]:\n",
    "                try:\n",
    "                    # Kyle note - might be good to do something else for consistency, since not all residues have CB\n",
    "                    dist = mut_residue['CB'] - open_strct[0][chain][residue]['CB']\n",
    "                    if dist < neighbor_distance:\n",
    "                        neighbors.add( (residue, chain) )\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        dist = mut_residue['CA'] - open_strct[0][chain][residue]['CA']\n",
    "                        if dist < neighbor_distance:\n",
    "                            neighbors.add( (residue, chain) )\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "def chi_angles(datadir, input_pdbs):\n",
    "    mutations = read_mutations_resfile(datadir)\n",
    "    \n",
    "    #http://www.ccp14.ac.uk/ccp/web-mirrors/garlic/garlic/commands/dihedrals.html\n",
    "    chi1_dict = {'ARG':['N','CA','CB','CG'],\n",
    "                 'ASN':['N','CA','CB','CG'],\n",
    "                 'ASP':['N','CA','CB','CG'],\n",
    "                 'CYS':['N','CA','CB','SG'],\n",
    "                 'GLN':['N','CA','CB','CG'],\n",
    "                 'GLU':['N','CA','CB','CG'],\n",
    "                 'HIS':['N','CA','CB','CG'],\n",
    "                 'ILE':['N','CA','CB','CG1'],\n",
    "                 'LEU':['N','CA','CB','CG'],\n",
    "                 'LYS':['N','CA','CB','CG'],\n",
    "                 'MET':['N','CA','CB','CG'],\n",
    "                 'PHE':['N','CA','CB','CG'],\n",
    "                 'PRO':['N','CA','CB','CG'],\n",
    "                 'SER':['N','CA','CB','OG'],\n",
    "                 'THR':['N','CA','CB','OG1'],\n",
    "                 'TRP':['N','CA','CB','CG'],\n",
    "                 'TYR':['N','CA','CB','CG'],\n",
    "                 'VAL':['N','CA','CB','CG1']}\n",
    "    chi2_dict = {'ARG':['CA','CB','CG','CD'],\n",
    "                 'ASN':['CA','CB','CG','OD1'],\n",
    "                 'ASP':['CA','CB','CG','OD1'],\n",
    "                 'GLN':['CA','CB','CG','CD'],\n",
    "                 'GLU':['CA','CB','CG','CD'],\n",
    "                 'HIS':['CA','CB','CG','ND1'],\n",
    "                 'ILE':['CA','CB','CG1','CD'],\n",
    "                 'LEU':['CA','CB','CG','CD1'],\n",
    "                 'LYS':['CA','CB','CG','CD'],\n",
    "                 'MET':['CA','CB','CG','SD'],\n",
    "                 'PHE':['CA','CB','CG','CD1'],\n",
    "                 'PRO':['CA','CB','CG','CD'],\n",
    "                 'TRP':['CA','CB','CG','CD1'],\n",
    "                 'TYR':['CA','CB','CG','CD1']}\n",
    "    \n",
    "    xangles_dict = {}\n",
    "    \n",
    "    for mutation in mutations:\n",
    "        print mutation\n",
    "        xangles_dict['%s%s' %(mutation[0], mutation[1])] = {}\n",
    "        counter = 1\n",
    "        for input_pdb in input_pdbs:\n",
    "            p = prody.parsePDB(input_pdb)\n",
    "            hv = p.getHierView()\n",
    "            \n",
    "            current_res = hv[mutation[1], int(mutation[0])]\n",
    "            templist = []\n",
    "            \n",
    "            \n",
    "            if current_res.getResname() in chi1_dict.keys():\n",
    "                current_res.select('name %s' %chi1_dict[current_res.getResname()])\n",
    "                chi1 = calcDihedral(current_res.select('name %s' %chi1_dict[current_res.getResname()][0]),\n",
    "                                    current_res.select('name %s' %chi1_dict[current_res.getResname()][1]),\n",
    "                                    current_res.select('name %s' %chi1_dict[current_res.getResname()][2]),\n",
    "                                    current_res.select('name %s' %chi1_dict[current_res.getResname()][3]))\n",
    "                templist.append(chi1[0])\n",
    "                \n",
    "            if current_res.getResname() in chi2_dict.keys():\n",
    "                chi2 = calcDihedral(current_res.select('name %s' %chi2_dict[current_res.getResname()][0]),\n",
    "                                    current_res.select('name %s' %chi2_dict[current_res.getResname()][1]),\n",
    "                                    current_res.select('name %s' %chi2_dict[current_res.getResname()][2]),\n",
    "                                    current_res.select('name %s' %chi2_dict[current_res.getResname()][3]))\n",
    "                templist.append(chi2[0])\n",
    "                \n",
    "            xangles_dict['%s%s' %(mutation[0], mutation[1])]['%s' %counter] = templist\n",
    "            \n",
    "            counter = counter + 1\n",
    "            \n",
    "        print xangles_dict\n",
    "\n",
    "def main():\n",
    "    #os.chdir('/home/james.lucas/Rotation/DDGBenchmarks_Test/')\n",
    "    os.chdir('/Users/jameslucas/Kortemme_Rotation')\n",
    "    #Define things\n",
    "    datadir = 'TestJobs/data/59648/'\n",
    "    reference = 'TestJobs/data/59648/1TM1_EI.pdb'\n",
    "    outputdir = 'TestJobs/output/59648/'\n",
    "    \n",
    "    input_temp = []\n",
    "    for i in os.listdir(outputdir):\n",
    "        if i.endswith('.pdb'):\n",
    "            input_temp.append(os.path.join(outputdir, i ))\n",
    "    input_pdbs = sorted(input_temp)\n",
    "    \n",
    "    neighbors = find_neighbors(datadir, reference, 8)\n",
    "    \n",
    "    chi_angles(datadir, input_pdbs)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Kyle's RMSD Script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "program_description = \"Script to calculate pairwise RMSD of ensemble\"\n",
    "\n",
    "# Use pyRMSD for RMSD calculations if available as it's much faster than BioPython\n",
    "try:\n",
    "    import pyRMSD\n",
    "    from pyRMSD.matrixHandler import MatrixHandler\n",
    "    import pyRMSD.RMSDCalculator\n",
    "    from pyRMSD.availableCalculators import availableCalculators\n",
    "    # Use CUDA for GPU calculations, if avialable\n",
    "    if 'QCP_CUDA_MEM_CALCULATOR' in availableCalculators():\n",
    "        pyrmsd_calc = 'QCP_CUDA_MEM_CALCULATOR'\n",
    "    else:\n",
    "        pyrmsd_calc = 'QCP_SERIAL_CALCULATOR'\n",
    "except ImportError:\n",
    "    print 'Warning: could not import faster RMSD module. Falling back to slower biopython...'\n",
    "    pyRMSD = None\n",
    "    import Bio.PDB\n",
    "    import Bio.PDB.Atom as Atom\n",
    "\n",
    "def calc_rms(ref_coords, alt_coords):\n",
    "    # print ref_coords, alt_coords\n",
    "    assert( len(ref_coords) == len(alt_coords) )\n",
    "    if pyRMSD:\n",
    "        calculator = pyRMSD.RMSDCalculator.RMSDCalculator(pyrmsd_calc, np.array([ref_coords, alt_coords]))\n",
    "        return calculator.pairwiseRMSDMatrix()[0]\n",
    "    else:\n",
    "        super_imposer = Bio.PDB.Superimposer()\n",
    "        ref_atoms = [Atom.Atom('CA', coords, 0.0, 1.0, '', ' CA ', i+1, element='C') for i, coords in enumerate(ref_coords)]\n",
    "        alt_atoms = [Atom.Atom('CA', coords, 0.0, 1.0, '', ' CA ', i+1, element='C') for i, coords in enumerate(alt_coords)]\n",
    "        super_imposer.set_atoms(ref_atoms, alt_atoms)\n",
    "        return super_imposer.rms\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=program_description)\n",
    "\n",
    "    parser.add_argument('-d', '--database_input',\n",
    "                        nargs = '+',\n",
    "                        help = 'Database to read coordinates from')\n",
    "    parser.add_argument('-f', '--folder',\n",
    "                        nargs = '+',\n",
    "                        help = 'Folder to search for PDB files')\n",
    "    parser.add_argument('-p', '--pdb_file',\n",
    "                        nargs = '+',\n",
    "                        help = 'PDB file to cluster')\n",
    "    parser.add_argument('--single_thread',\n",
    "                        default = False,\n",
    "                        action = 'store_true',\n",
    "                        help = 'Do not use multiprocessing')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.single_thread:\n",
    "        cpu_count = 1\n",
    "    else:\n",
    "        cpu_count = multiprocessing.cpu_count()\n",
    "        pool = multiprocessing.Pool(cpu_count)\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    print 'Starting calculating RMS for all paths vs. all first fragments for each position'\n",
    "    total_count = len(path_data)\n",
    "    starting_time = time.time()\n",
    "\n",
    "    def helper_callback(outer_results):\n",
    "        for results_tuple in outer_results:\n",
    "            path_number, rms_results = results_tuple\n",
    "            results_dict[path_number] = rms_results\n",
    "\n",
    "    path_nums_for_jobs = [[] for x in xrange(cpu_count)]\n",
    "    path_coords_for_jobs = [[] for x in xrange(cpu_count)]\n",
    "    for i, path_coords in enumerate([[anchor_points[x] for x in path] for path in path_data]):\n",
    "        path_nums_for_jobs[ i%cpu_count ].append( i )\n",
    "        path_coords_for_jobs[ i%cpu_count ].append( path_coords )\n",
    "\n",
    "    for path_nums_list, path_coords_list in zip(path_nums_for_jobs, path_coords_for_jobs):\n",
    "        if args.single_thread:\n",
    "            helper_callback( paths_against_all_fragments(path_nums_list, path_coords_list, starting_time, total_count, path_length) )\n",
    "        else:\n",
    "            pool.apply_async(paths_against_all_fragments, (path_nums_list, path_coords_list, starting_time, total_count, path_length), callback=helper_callback)\n",
    "\n",
    "    if not args.single_thread:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    n = int(reporter_n.value)\n",
    "    completion_time = time.time()\n",
    "    print 'Finished! Processed %d %s, took %.3f seconds\\n' % (n, 'paths', completion_time-starting_time)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
